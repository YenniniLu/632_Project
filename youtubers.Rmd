---
title: "632 Project"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
```

```{r message=FALSE}
library(tidyverse)
library(stringr)
library(randomForest) 
library(vip) 
library(rpart)
library(rpart.plot)
library(caret)
library(tidytext)
```

## Research Data

The dataset contains **2515 unique videos** and their **subtitles** from over **91 different YouTubers**, ranging from all different kinds of categories. 

```{r}
df_raw <- read.csv("data.csv")
head(df_raw)
```

![](assets/video.png)

## Research Goal

Do a sentiment analysis on the subtitles and find the best multiple linear regression model to predict the number of views using Subscribers, CC, Released, Category, Sentiment and Length.

## Tasks

1. Data Cleaning.       
2. Conduct a sentiment analysis on the subtitles.         
3. Try various statistical models like linear regression, decision tree and random forest.        
4. Compare these models in terms of prediction performation and interpretability.       

## Data Cleaning


```{r}
df_raw %>% select(Views, Subscribers, Released, Length) %>% head(10)
```

Looking at the data, we notice several problems in the data, like:     

1. Views: The Views variable is in string format and the units are different, like "10K views", "10M views". We prefer it to be in number and in the same unit in order to conduct statistical analysis.       

2. Subscribers: The same problems as Views. The Subscribers variable is like "10K subscribers", "10M subscribers".       

3. Length: The video length is in string format, like "12:00", "1:12:00". We need it to be in number and in the same unit.       

4. Released: The Released variable is in string format, like "2 years age", "10 month ago". We need it to be in number and in the same unit.        

Therefore, we need to do data cleaning first.

```{r eval=FALSE}
# Unify units and convert string to number, like: 10K views -> 10, 10M views -> 10000
cleanViews <- function(str) {
  str <- str_remove(str, " views")
  last <- str_sub(str, -1)
  views <- str %>% str_remove(last) %>% as.numeric()
  if (last == "M") return(1000*views)
  else return(views)
}

# Unify units and convert string to number, like: 10K subscribers -> 10, 10M subscribers -> 10000
cleanSubscribers <- function(str) {
  str <- str_remove(str, " subscribers")
  last <- str_sub(str, -1)
  views <- str %>% str_remove(last) %>% as.numeric()
  if (last == "M") return(1000*views)
  else return(views)
}

# Convert time in string format to number of minutes, like: 12:00 -> 12, 1:12:00 -> 72
cleanLength <- function(str) {
  list <- str_split(str, ":")
  len <- length(list[[1]])
  if (len == 3) {
     h <- as.numeric(list[[1]][1])
     m <- as.numeric(list[[1]][2])
     return((m + 1) + 60*m)
  } else {
     m <- as.numeric(list[[1]][1])
     return(m+1)
  }
}

# Convert time to number of months ago, like: 1 years ago -> 12, 10 months ago to 10
cleanReleased <- function(str) {
  str <- str_remove(str, "Streamed ")
  list <- str_split(str, " ")
  if (list[[1]][2] == "years") return(as.numeric(list[[1]][1])*12)
  else return(as.numeric(list[[1]][1]))
}

# Remove NAs
df <- df_raw %>%  
  filter(
    !is.na(Released) & Released != ""
  ) 

# Clean the data
df <- df %>% mutate(
  Views = map_dbl(Views, cleanViews),
  Subscribers = map_dbl(Subscribers, cleanSubscribers),
  Length = map_dbl(Length, cleanLength),
  Released = map_dbl(Released, cleanReleased)
)

df %>% select(Views, Subscribers, Released, Length) %>% head(10)

# Save for future use
write_csv(df, "cleaned_data.csv")
```
After cleaning, Views, Subscribers, Released and Length are numbers, while Views, Subscribers are in K and Released and Length are in minute.

## Data Discovery

```{r}
df <- read_csv("cleaned_data.csv")
df$CC <- as.factor(df$CC)
df$Category <- as.factor(df$Category)
df$Subscribers <- as.numeric(df$Subscribers)

head(df)
```

```{r}
table(df$CC)
boxplot(log(Views) ~ CC, data = df)

summary(df$Length)
summary(df$Released)
summary(df$Subscribers)

pairs(Views ~ CC + Released + Length + Subscribers + Category, data=df)
```

## Sentiment Analysis / Text mining

TODO by Xinyi
```{r}
df_script <- df %>% 
  select(Title, Transcript)
head(df_script)
```


```{r}
data("stop_words")
custom_stop_words <- rbind(stop_words, c("_", "custom"))
```

```{r}
#bigram
df_script %>% 
  group_by(Title) %>% 
  unnest_tokens(word, Transcript, token = "ngrams", n = 2) 
```



```{r}
df_script<- df_script %>% 
  group_by(Title) %>% 
  unnest_tokens(word, Transcript) %>% 
  anti_join(custom_stop_words) %>% 
  count(word, sort = TRUE) %>% 
  mutate(total = sum(n)) %>% 
  ungroup()
  #inner_join(get_sentiments("afinn")) #%>% 
  #summarise(sentiment = sum(value))
  #mutate(total = sum(word)) %>% 
  #mutate(perc = round(n/total, 2))

head(df_script)
```

```{r}
df_script %>% 
  group_by(Title) %>% 
  inner_join(get_sentiments("afinn")) %>% 
  mutate(afinn_score = sum(value)) %>% 
  mutate(perc = round(n/total, 2))
```



## Preparation for Cross-Validation

Randomly split the data set in a 70% training and 30% test set. Make sure to use set.seed() so that your results are reproducible
 
```{r}
set.seed(652)
n <- nrow(df)
train_index <- sample(1:n, round(0.7*n))
df_train <- df[train_index,]
df_test <- df[-train_index,]
```

## Linear Regression

```{r}
lm1 <- lm(Views ~ CC + Released + Length + Subscribers, data=df)
summary(lm1)
```


## Regression Tree

### Fit a regression tree on the training set.

```{r}
# Fit tree model
t1 <- rpart(Views ~ CC + Released + Category + Length + Subscribers,
            data = df_train,
            method = "anova")

# Plot the desicion tree
rpart.plot(t1)

# Plot R-square vs Splits and the Relative Error vs Splits.
rsq.rpart(t1)
```

### Make predictions on the test set and compute the RMSE

```{r}
# Make prediction
pred_tree <- predict(t1, newdata = df_test)

# Compute the RMSE
RMSE(df_test$Views, pred_tree)
```

## Random Forest

### Fit a Random Forest on the training set usinng the defaults for mtry and ntree.

```{r}
set.seed(652)
rf1 <- randomForest(Views ~ CC + Released + Category + Length + Subscribers, importance = TRUE, data = df_train)
rf1
```

Use the `vip()` function to make a variable importance plot.  Which variables are most important? 

```{r}
vip(rf1, num_features = 14,  include_type = TRUE)
```

### Make predictions on the test set and compute the RMSE

```{r}
# Make prediction
pred_rf <- predict(rf1, newdata = df_test)

# Compute the RMSE
RMSE(df_test$Views, pred_rf)
```

## Conclusion(TODO)

Model | RMSE | R Squared | Number of Coefficients | performance | interpretability
---- | ---- | ---- | ---- | ---- | ----
linear regression | - | - | - | - | -
regression tree | - | - | - | - | -
random forest | - | - | - | - | -

### Regression Tree VS Random Forest 

Aggregated/ensemble models are not universally better than their "single" counterparts, they are better if and only if the single models suffer of instability. With XX training rows and only XX columns, we are in a comfortable training sample size situation in which even a decision tree may get reasonably stable.



