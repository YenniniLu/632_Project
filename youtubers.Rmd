---
title: "632 Project"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
```

```{r message=FALSE}
library(tidyverse)
library(dplyr)
library(stringr)
library(randomForest) 
library(vip) 
library(rpart)
library(rpart.plot)
library(caret)
library(tidytext)
library(tidyr)
library(MASS)
library(car)
```

## Research Data

The dataset contains **2515 unique videos** and their **subtitles** from over **91 different YouTubers**, ranging from all different kinds of categories. 

```{r}
df_raw <- read.csv("data.csv")
head(df_raw)
```

![](assets/video.png)

## Research Goal

Do a sentiment analysis on the subtitles and find the best multiple linear regression model to predict the number of views using Subscribers, CC, Released, Category, Sentiment and Length.

## Tasks

1. Data Cleaning.       
2. Conduct a sentiment analysis on the subtitles.         
3. Try various statistical models like linear regression, decision tree and random forest.        
4. Compare these models in terms of prediction performation and interpretability.       

## Data Cleaning


```{r}
df_raw %>% dplyr::select(URL, Channel, Views, Subscribers, Released, Length) %>% head(10)
```

Looking at the data, we notice several problems in the data, like:     

1. Views: The Views variable is in string format and the units are different, like "10K views", "10M views". We prefer it to be in number and in the same unit in order to conduct statistical analysis.       

2. Subscribers: The same problems as Views. The Subscribers variable is like "10K subscribers", "10M subscribers".       

3. Length: The video length is in string format, like "12:00", "1:12:00". We need it to be in number and in the same unit.       

4. Released: The Released variable is in string format, like "2 years age", "10 month ago". We need it to be in number and in the same unit.        

Therefore, we need to do data cleaning first.

```{r eval=FALSE}
# Unify units and convert string to number, like: 10K views -> 10, 10M views -> 10000
cleanViews <- function(str) {
  str <- str_remove(str, " views")
  last <- str_sub(str, -1)
  views <- str %>% str_remove(last) %>% as.numeric()
  if (last == "M") return(1000*views)
  else return(views)
}

# Unify units and convert string to number, like: 10K subscribers -> 10, 10M subscribers -> 10000
cleanSubscribers <- function(str) {
  str <- str_remove(str, " subscribers")
  last <- str_sub(str, -1)
  views <- str %>% str_remove(last) %>% as.numeric()
  if (last == "M") return(1000*views)
  else return(views)
}

# Convert time in string format to number of minutes, like: 12:00 -> 12, 1:12:00 -> 72
cleanLength <- function(str) {
  list <- str_split(str, ":")
  len <- length(list[[1]])
  if (len == 3) {
     h <- as.numeric(list[[1]][1])
     m <- as.numeric(list[[1]][2])
     return((m + 1) + 60*h)
  } else {
     m <- as.numeric(list[[1]][1])
     return(m+1)
  }
}

# Convert time to number of months ago, like: 1 years ago -> 12, 10 months ago to 10
cleanReleased <- function(str) {
  str <- str_remove(str, "Streamed ")
  list <- str_split(str, " ")
  if (list[[1]][2] == "years") return(as.numeric(list[[1]][1])*12)
  else return(as.numeric(list[[1]][1]))
}

# Remove NAs
df <- df_raw %>%  
  na.omit() %>%
  filter(
    Released != "",
    Title != "",
    Transcript != ""
  ) 

# Clean the data
df <- df %>% mutate(
  Views = map_dbl(Views, cleanViews),
  Subscribers = map_dbl(Subscribers, cleanSubscribers),
  Length = map_dbl(Length, cleanLength),
  Released = map_dbl(Released, cleanReleased)
)

df %>% dplyr::select(URL, Channel, Views, Subscribers, Released, Length) %>% head(10)

# Save for future use
write_csv(df, "cleaned_data.csv")
```
After cleaning, Views, Subscribers, Released and Length are numbers, while Views, Subscribers are in K and Released and Length are in minute.

## Data Discovery / Diagnostics for Linear Regression

```{r}
df <- read_csv("cleaned_data.csv")
df$CC <- as.factor(df$CC)
df$Category <- as.factor(df$Category)
df$Subscribers <- as.numeric(df$Subscribers)

head(df)
```

```{r}
table(df$CC)
boxplot(log(Views) ~ CC, data = df)

hist(df$Length, xlab = "Minutes", breaks = 50)
summary(df$Length) 

summary(df$Released)
hist(df$Released, xlab = "Month Ago")

summary(df$Subscribers)
hist(df$Subscribers, xlab = "K Subscribers")

pairs(Views ~ CC + Released + Length + Subscribers + Category, data=df)
```


```{r}
hist(df$Views)
```
From the diagnostics, Views, Subscribers, Released and Length need log transformation.


## Sentiment Analysis / Text mining

TODO by Xinyi
```{r}
df_script <- df %>% 
  dplyr::select(Id, Title, Transcript)
head(df_script)
```

```{r, eval=FALSE}
# just use this code to watch the video to check the transcript
df %>% 
  filter(Title == "Former CIA Agent Breaks Down Jeffrey Epstein Case")
```


```{r}
data("stop_words")
custom_stop_words <- rbind(stop_words, c("_", "custom"))
```

```{r, eval=FALSE}
#bigram
 bigrams_separated <- df_script %>% 
  group_by(Id) %>% 
  # unnest Transcript in bigram format
  unnest_tokens(bigram, Transcript, token = "ngrams", n = 2) %>% 
  separate(bigram, c("word1", "word2"), sep = " ") %>% # separate bigram 
  filter(!word1 %in% custom_stop_words$word) %>% # filter out all the stop words
  filter(!word2 %in% custom_stop_words$word) 
  
bigrams_united <- bigrams_separated %>% 
  unite(bigram, word1, word2, sep = " ")  # unite words back together

```

```{r, eval=FALSE}
head(bigrams_separated)
```





```{r, eval=FALSE}
# Using bigrams to provide context in sentiment analysis
# not in presentation!!
negation_words <- c("not", "no", "never", "without")

bigrams_separated %>%
  filter(word1 %in% negation_words) %>%
  inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
  count(word1, word2, value, sort = TRUE)

```


```{r}
df_word <- df %>% 
  group_by(Id) %>% 
  unnest_tokens(word, Transcript) %>% 
  anti_join(custom_stop_words) %>% 
  count(word, sort = TRUE) %>% 
  mutate(total = sum(n)) %>% 
  ungroup()
  #inner_join(get_sentiments("afinn")) #%>% 
  #summarise(sentiment = sum(value))
  #mutate(total = sum(word)) %>% 
  #mutate(perc = round(n/total, 2))

head(df_word)
```

```{r}
df_title_word <- df %>% 
  group_by(Id) %>% 
  unnest_tokens(word, Title) %>% 
  anti_join(custom_stop_words) %>% 
  count(word, sort = TRUE) %>% 
  mutate(total = sum(n)) %>% 
  ungroup()
  #inner_join(get_sentiments("afinn")) #%>% 
  #summarise(sentiment = sum(value))
  #mutate(total = sum(word)) %>% 
  #mutate(perc = round(n/total, 2))

head(df_title_word)
```





# Below codes:
### use tf-idf to find the importance of a word in the transcript, then times it to a word's afinn score, and sum up all the words' socre to a video afinn_score.
### Will use "afinn_score" to represent the sentiment score in the regression modeling!

# Transcript sentiment

```{r}
df_afinn <- df_word %>% 
  left_join(get_sentiments("afinn")) %>% 
  #mutate(afinn_score = sum(value)) %>% 
  #mutate(perc = round(n/total, 2)) %>% 
  group_by(Id) %>% 
  bind_tf_idf(word, Id, n) %>% 
  mutate(value = ifelse(is.na(value), 0, value)) %>%
  mutate(afinn_score = sum(value*tf_idf)) %>%
  ungroup() 
  #filter(Title == "2018 Jeep Trackhawk Review - The SUV That's Quicker Than a Supercar")

head(df_afinn)
```

```{r}
df_afinn <- df_afinn %>% 
  dplyr::select(Id, afinn_score) %>% 
  unique() %>% 
  ungroup()

df_afinn
```


```{r}
summary(df_afinn$afinn_score)
```

```{r}
hist(df_afinn$afinn_score)
```

# Title sentiment
```{r}
df_title_afinn <- df_title_word %>% 
  left_join(get_sentiments("afinn")) %>% 
  #mutate(afinn_score = sum(value)) %>% 
  #mutate(perc = round(n/total, 2)) %>% 
  group_by(Id) %>% 
  bind_tf_idf(word, Id, n) %>% 
  mutate(value = ifelse(is.na(value), 0, value)) %>%
  mutate(afinn_title_score = sum(value*tf_idf)) %>%
  ungroup() 
  #filter(Title == "2018 Jeep Trackhawk Review - The SUV That's Quicker Than a Supercar")

head(df_title_afinn)
```


```{r}
df_title_afinn <- df_title_afinn %>% dplyr::select(Id, afinn_title_score) %>% 
  unique() %>% 
  ungroup()

head(df_title_afinn)
```



```{r}
summary(df_title_afinn$afinn_title_score)
```

```{r}
hist(df_title_afinn$afinn_title_score)
```



```{r}
df1 <- df %>% 
  left_join(df_afinn) %>% 
  left_join(df_title_afinn) %>% 
  mutate(
    afinn_title_score = ifelse(is.na(afinn_title_score), 0, afinn_title_score)
  ) %>% 
  unique() 


head(df1)
```

```{r eval=FALSE}
# Save for future use
write_csv(df1, "cleaned_data_with_sentiment.csv")
```


## Preparation for Cross-Validation

Randomly split the data set in a 70% training and 30% test set. Make sure to use set.seed() so that your results are reproducible
 
```{r}
df1 <- read_csv("cleaned_data_with_sentiment.csv")
df1$CC <- as.factor(df1$CC)
df1$Category <- as.factor(df1$Category)
df1$Subscribers <- as.numeric(df1$Subscribers)

set.seed(652)
n <- nrow(df1)
train_index <- sample(1:n, round(0.7*n))
df_train <- df1[train_index,]
df_test <- df1[-train_index,]

# function to compute RMSE
RMSE <- function(y, y_hat) {
  sqrt(mean((y - y_hat)^2))
}
```

## Linear Regression
```{r}
# original response and predictors
pairs(Views ~ CC + Released + 
        Length + Subscribers + Category + 
        afinn_score + afinn_title_score, 
      data=df1)
```

From the plot above, we didn't see any obvious strong correlation between the predictors.


```{r}
# log reponse and other predictors that are right skewed
pairs(log(Views) ~ CC + log(Released) + 
        log(Length) + log(Subscribers) + Category + 
        afinn_score + afinn_title_score, 
      data=df1)
```
From the plot above, we didn't see any obvious strong correlation between the predictors.


```{r}
round(cor(df1[, c(3,7,11,12,13)]), 2)
```


The correlation table also indicates this.



```{r, eval=FALSE}
plot(log(Views)~ afinn_score, data = df1)
```


```{r, eval=FALSE}
plot(log(Views)~ afinn_title_score, data = df1)
```


```{r}
boxcox(Views ~ CC + log(Released) + log(Length) + log(Subscribers) + Category + afinn_score + afinn_title_score,
       data=df1,
       lambda = seq(-3, 3, by = 0.05))
```



```{r}
summary(powerTransform(Views ~ 
                         CC + log(Released) + log(Length) +
                         log(Subscribers) + Category + afinn_score + afinn_title_score, 
                       data=df1))
```


```{r}
lm_full <- lm(Views ~ CC + Released + Length + Subscribers + Category + afinn_score+ afinn_title_score, data=df1)
summary(lm_full)
```


```{r}
# include all the predictors and with log transf's
lm1 <- lm(log(Views) ~ CC + log(Released) + log(Length) + log(Subscribers) + Category + afinn_score+ afinn_title_score, data=df1)
summary(lm1)
```


## check variance inflation factors by faraway::vif()
```{r}
round(faraway::vif(lm_full), 2)
```


```{r}
round(faraway::vif(lm1), 2)
```



```{r}
plot(predict(lm1), resid(lm1), xlab = "Fitted values", ylab = "Residuals")
abline(h=0)
```

```{r}
par(mfrow=c(1,2))
hist(resid(lm1))
qqnorm(resid(lm1))
qqline(resid(lm1))
```



```{r}
# remove log(Length) / Length
lm2 <- lm(log(Views) ~ CC + log(Length) + log(Subscribers) + Category + afinn_score + afinn_title_score, data=df1)
summary(lm2)
```

```{r}
plot(predict(lm2), resid(lm2), xlab = "Fitted values", ylab = "Residuals")
abline(h=0)
```


```{r}
par(mfrow=c(1,2))
hist(resid(lm2))
qqnorm(resid(lm2))
qqline(resid(lm2))
```


```{r}
# remove log(Length) / Length, afinn_score and afinn_title_score
lm3 <- lm(log(Views) ~ CC  + log(Length) + log(Subscribers) + Category, data=df1)
summary(lm3)
```


```{r}
plot(predict(lm3), resid(lm3), xlab = "Fitted values", ylab = "Residuals")
abline(h=0)
```

```{r}
par(mfrow=c(1,2))
hist(resid(lm3))
qqnorm(resid(lm3))
qqline(resid(lm3))
```

# variable selection
```{r}
# lm1 <- lm(log(Views) ~ CC + log(Released) + log(Length) + log(Subscribers) + Category + afinn_score+ afinn_title_score)
lm4 <- step(lm1)
summary(lm4)
```


```{r}
plot(predict(lm4), resid(lm4), xlab = "Fitted values", ylab = "Residuals")
abline(h=0)
```

```{r}
par(mfrow=c(1,2))
hist(resid(lm4))
qqnorm(resid(lm4))
qqline(resid(lm4))
```

```{r}
# fit lm4 (the final model in MLR part) to df_train:
# lm(formula = log(Views) ~ CC + log(Length) + log(Subscribers) + Category + afinn_score, data = df1)
lm5 <- lm(log(Views) ~ CC + log(Length) + log(Subscribers) + Category + afinn_score, data = df_train)


# make prediction
pred1 <- predict(lm5, newdata = df_test)
pred_lm5 <- exp(pred1); length(pred_lm5)


# Compute the RMSE
lm_RMSE <- RMSE(df_test$Views, pred_lm5); lm_RMSE
```


## Regression Tree

### Fit a regression tree on the training set.

```{r}
# Fit tree model
t1 <- rpart(Views ~ CC + Released + Category + Length + Subscribers + afinn_score + afinn_title_score,
            data = df_train,
            method = "anova")
summary(t1)

# Plot the desicion tree
rpart.plot(t1)

# Plot R-square vs Splits and the Relative Error vs Splits.
rsq.rpart(t1)
```


### Make predictions on the test set and compute the RMSE

```{r}
# Make prediction
pred_tree <- predict(t1, newdata = df_test)

# Compute the RMSE
t1_RMSE <- RMSE(df_test$Views, pred_tree); t1_RMSE
```

```{r}
# test R^2
t1_R2 <- cor(df_test$Views, pred_tree)^2; t1_R2
```

### Example of interptiation:
Since the test set R2 for the second model is higher (closer to 1) it performs better. The interpretation is that about 67% of the variability in Sale_Price, on the test set, is explained by predictions from the linear regression model with Gr_Liv_Area and Year_Built as predictor variables.


## Random Forest

### Fit a Random Forest on the training set usinng the defaults for mtry and ntree = 500.
### default mtry: p/3 = 28/3 = 9 (mtry: Number of predictors randomly sampled as candidates at each split.)


```{r}
length(lm_full$coefficients)
```

```{r}
set.seed(652)
rf1 <- randomForest(Views ~ CC + Released + Category + 
                      Length + Subscribers + afinn_score + 
                      afinn_title_score, importance = TRUE, 
                    data = df_train)
rf1
```

Use the `vip()` function to make a variable importance plot.
# Use below to do interpreation with random forests.
## i.e. In this rf model, we know that to predict the Views of a youtube viedo, the most important predictor is Subscribers of Channel, and then is the Video's Category, and the Length of Video. 



```{r}
vip(rf1, num_features = 14,  include_type = TRUE)
```

```{r}
plot(c(1: 500), rf1$mse, xlab="ntree", ylab="MSE", type="l")
```


### Make predictions on the test set and compute the RMSE

```{r}
# Make prediction
pred_rf <- predict(rf1, newdata = df_test); length(pred_rf)

# Compute the RMSE
rf1_RMSE <- RMSE(df_test$Views, pred_rf); rf1_RMSE
```

```{r}
# test R^2
rf1_R2 <- cor(df_test$Views, pred_rf)^2; rf1_R2
```


```{r}
pred_df <- data.frame(
  Actual = df_test$Views, 
  Pred_RF = pred_rf,
  Pred_LM = pred_lm5
) 
```


```{r}
ggplot(pred_df, aes(x = Actual, y = Pred_RF)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) +
  xlab("Actual Views") + ylab("Predicted Views") +
  ggtitle("Random Forests") 
```

```{r}
ggplot(pred_df, aes(x = Actual, y = Pred_LM)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1) +
  xlab("Actual Views") + ylab("Predicted Views") +
  ggtitle("Linear Regression") 
```


## Conclusion(TODO)

```{r}
# lm(Views ~ CC + Released + Length + Subscribers + Category + afinn_score+ afinn_title_score, data=df1)
summary(lm_full)$r.squared
# lm(log(Views) ~ CC + log(Released) + log(Length) + log(Subscribers) + Category + afinn_score+ afinn_title_score, data=df1)
summary(lm1)$r.squared 
# lm(log(Views) ~ CC + log(Length) + log(Subscribers) + Category + afinn_score + afinn_title_score, data=df1)
summary(lm2)$r.squared
# lm(log(Views) ~ CC  + log(Length) + log(Subscribers) + Category, data=df1)
summary(lm3)$r.squared
# lm(formula = log(Views) ~ CC + log(Length) + log(Subscribers) + Category + afinn_score, data = df1)
summary(lm4)$r.squared
# lm(formula = log(Views) ~ CC + log(Length) + log(Subscribers) + Category + afinn_score, data = df_train)
summary(lm5)$r.squared
```


```{r}
summary(lm_full)$adj.r.squared
summary(lm1)$adj.r.squared
summary(lm2)$adj.r.squared
summary(lm3)$adj.r.squared
summary(lm4)$adj.r.squared
summary(lm5)$adj.r.squared
```

```{r}
t1_R2 # regression tree's R2
rf1_R2 # Random forest' R2
```

```{r}
lm_RMSE # lm5's RMSE
t1_RMSE # regression tree's RMSE
rf1_RMSE # Random forest' R2
```




```{r}
# test R^2 for regression tree
cor(df_test$Views, pred_tree)^2

# test R^2 for random forest
cor(df_test$Views, pred_rf)^2

```


```{r}
data.frame(Model=c("full model without transformation", "lm1", "lm2", "lm3", "lm4", "lm5", "regression tree", "random forest"),
           R_squared = c(summary(lm_full)$r.squared,
                         summary(lm1)$r.squared,
                         summary(lm2)$r.squared,
                         summary(lm3)$r.squared,
                         summary(lm4)$r.squared,
                         summary(lm5)$r.squared,
                         cor(df_test$Views, pred_tree)^2,
                         cor(df_test$Views, pred_rf)^2),
           adj_R_squared = c(summary(lm_full)$adj.r.squared,
                             summary(lm1)$adj.r.squared,
                             summary(lm2)$adj.r.squared,
                             summary(lm3)$adj.r.squared,
                             summary(lm4)$adj.r.squared,
                             summary(lm5)$adj.r.squared,
                             NA,
                             NA),
           RMSE = c(NA, NA, NA, NA, NA,
                    lm_RMSE,
                    t1_RMSE,
                    rf1_RMSE))
```



Model | RMSE | R Squared | adj R Square | Number of coefficients   
--------- | --------- | --------- | --------- | 
linear regression | 7618.171 | 0.8162162 | 0.8130322 | 26 | 
regression tree | 7977.73 | 0.7801641 | - | - | 
random forest | 6660.282 | 0.836752 | - | - | 

### Linear Regression vs Regression Tree VS Random Forest 

Aggregated/ensemble models are not universally better than their "single" counterparts, they are better if and only if the single models suffer of instability. With XX training rows and only XX columns, we are in a comfortable training sample size situation in which even a decision tree may get reasonably stable.




